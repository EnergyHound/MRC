
![DAI-ecosystem](https://github.com/DecentralizeAI/MRC/assets/76454555/d4be1474-3046-4fc3-8803-a880038b78aa)

# Building Decentralized AI

On December 9, 2023 the Decentralized AI community assembled from around the world at Kiretsu in Austin, Texas in order to begin contributing to this repository.

The objectives are to define:
- 1. The tech stack for Decentralized AI
- 2. Practical technical standards for collaboration within in the community.

Morpheus encourages and will incentivize developers who propose or implement new standards/integrations between open source projects in DeAI.

Live Journal

## Morpheus - David A. Johnston
- Website: <https://mor.org/> 
- Github: <https://github.com/MorpheusAIs/Morpheus>
- David's X Profile: <https://twitter.com/DJohnstonEC>

Morpheus is designed to incentivize the first peer-to-peer network of personal AIs, known as Smart Agents. Providing users open-source Smart Agents to connect to their wallets, Dapps, & smart contracts promises to open the world of Web3 to everyone.

**Key points:**

- 230 days left until July 26, 2024 - the date the commerce department is mandated to deterine if open source weights constitute munitions
- [EO signed on October 31st](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/) 
- Limits number of parameters models can have
        - limit for permissionless models at 10B parametrs and only 20gigs
         - KYC for data centers
- Only an 8 month timeline to build open source tech stack

- permissionless building is the heart of what we’re trying to do

- Phil Zimmerman is the patron saint of decentralized AI
        - In 1991, a bill was introduced to ban encryption for email, so Phil introduced PGP, because privacy is a human right
        - He printed his work on a t shirt and was arrested for disclosing the RSA algorithm.
        - Won in supreme court based on free speech grounds, who recognized that code and speech were protected
- This is why your email can legally be have private
- A few weeks ago in SF the Keep AI Open event was announced and within 48 hours >700 people showed up at the end of OpenAI's dev day
- Marc Andreessen is constantly posting memes for decentralized AI
  - the right tot bear compute
  - come and take it
- Balaji Tweet:
    "free internet means free AI
    we will fight government control over compute with everything we have"
- Morpheus is decentralized open source AI, and the tech stack for decentralized AI
  - anonymous group dropped paper in September
  - within 45 days community had built implementation
  - live now can run on computer locally
  - fully open source LLM running on your data
  - MOR smart contracts entering testnet today
- We want this to continue beyond today
  - join discord
  - channel for every project os people can follow up with questions
  - engage with everyone building models, fine tuning, agents, every part of tech stack
- The goal is 1 billion users for decentralized AI
  - AI is the opportunity to get a billion people into crypto by removing technical barriers to access web3
  - With AI, we build off the expressed intent,
  - On Morpheus, it knows what smart contracts are available
- The AI community: needs censorship resistant compute and tools to monetize agents

# Dria - FirstBatch

Dria serves as a collective memory for AGI, where information is stored permanently in a format understandable to both humans and AI, ensuring universal accessibility.

Knowledge Hub consists of multi-region and serverless public vector databases called knowledge; curated from pdf, mp3, csv or other file types. It is fully decentralized and every index is available as a smart contract, making each Knowledge public and permanent.

## **Dria offers:**

- An API for knowledge retrieval implementing search with natural language and query.
- A docker image for running local APIs without permission.

## **Paving the way for open AGI: Core Solutions**

1) ***Cost of Knowledge at Its Lowest:***

Dria modernizes AI interfacing by indexing and delivering the world's knowledge via LLMs.

Dria's Public RAG Models Democratize knowledge access with cost-effective, shared RAG models.

Today, Dria is able to handle Wikipedia's 23GB database and annual 56 billion traffic efficiently at just $258.391, creating a base for world knowledge.

2) **Contributing is easy and incentivized for everyone:**

Dria's zero technical mumbo jumbo approach allows everyone to contribute knowledge to LLMs.

Drag & Drop Public RAG Model effortlessly transforms knowledge into a retrievable format with an intuitive drag-and-drop upload feature.

Users worldwide can contribute valuable knowledge to shared RAG knowledge in an environment where knowledge uploaders can earn rewards for the value of their verifiable work.

3) **Safe, Trust Minimized, and Open Collaboration:**

Anyone can run RAG models locally through smart contracts, enabling permissionless access to world knowledge.

Dria stores all of the world's knowledge into a public ledger called Arweave, a decentralized storage network designed to offer a platform for permanently storing data.

As Arweave's main value proposition is allowing users to store data permanently, once something is uploaded to the Arweave network, it's intended to be stored forever without the risk of data loss or degradation.

Full persistence ensures accountability against manipulative AI technologies that proliferate during elections, wars, and existential crises. Communities can reevaluate AI knowledge, establishing transparent mechanisms for safeguarding against manipulation.

## Anna Zazlauskas - Vana

Vana: Own your data

***Key points***

- data ownership
- goal: world where users own data and value it creates
- initial belief: token incentives enable large scale RLHF and data labelling
  - people who want to sell data do so out of desperation
  - not the best dataset
  - uphill fraud battle
  - people constantly finding ways to sell bad data
  - people who want to sell data for financial reward are not representative
  - mostly doing out of financial desperation
  - users choose products that align with ideologies, value privacy and agency
- Reality:
  - users choose whatever is most convenient or capable. privacy/security are afterthoughts.
  - slacktivism

- initial belief: data ownership legislation like GDPR and CCP will help.
  - regulation favors consumers.
- learning: even if users have a legal right ot data, it is inconvenient to access. users have to be very motivated.
  - regulation favors incumbent.

- you can ask for your labels on instagram

- On Vana:
  - make a personal data tangible through a personalized ai model
  - bring your model with you throughout internet
  - users host their own nodes or opt for a convenient hosted option
  - private data stays on user's node, while third party apps run inference.
  - granular permissions so you can let people access your data or models.

- Modalities:
  - image: train lora based on 10 photos of yourself
  - text: personality + memory stream from your social data and messages
  - audio( hosted) based on 1min of your voice
  - best audio models are closed source (?)

- memory architecture
  - query memories based on relevance, important, and recency
  - summarize relevant memories to fit in context window
  - for more, read Generative Agents: Interactive Simulacra of Human Behavior

- bootstrapped network by building viral consumer applications in house
  - 1.2M users
  - 700k private models trained
  - 10M personal data points

- collective models
  - users contribute data to models they collectively own and govern
  - users decide who can access the model, how much to charge, how it can be used
  - each collective has its own node, similar to a user’s node

- host your own vana node
  - connect your social data, journal entries, messages, other personal data with an ally that deeply understand you
  - everything stays on yoru machine
  - can open up an endpoint to use it throughout apps
  - reach out to <anna@vana.com> to try this out

## Ritual - Niraj

Integrate AI models into your protocol, application or smart contract with a few lines of code.

Described a global statistical computer.

__Key Points:__
- motivation:
    - ai is eating the world
    - usage going up massively
    - decentralized intelligence improving

*problems of AI today:*
- infrastructure highly centralized
    - model storage
    - model governance and ownership (e.g. OAI fiasco)
    - model compute (training, inference, fine tuning, etc)
    - access to training data
- ai infra is highly permissioned
    - high costs ot using/improving AI
    - permissioned centralized APIs to access
    - no privacy/computational integrity censorship resistance
    - most OSS models are highly red-teamed/censored
    - many geographical limitations
- AI infra is increasingly regulated
    - ai incumbents and governments attempting strong regulatory capture
    - “we know what’s in your best interests”

- future impact
    - as AI gets inserted into every tech product, new forms of censorship/manipulation ill take place
    - LLMs and other foundation models create highly engaging forms of propaganda (e.g. 2024 US election media)
    - political ideology weaponized by who controls distribution and access to models
    - open and transparent governance of AI models is key
    - “who controls models controls the world”

*AI x Crypto to the rescue*
- AI is highly centralizing tech
- crypto is highly decentralizing tech
- combining both solves aforementioned problems
- trustlessness + intelligence = ???won’t be evil -> can’t b evil
- if we’ve decentralized money, music, property records, etc, why not AI?

At Ritual:
- how do we get AI into hands of crypto devs today
- combine best of ai and crypto to make it easy for devs to build crypto x ai products
- model specific computational integrity (opML and zkmlO
- privacy (FHE for classical ML models, MPC for foundation models)
- ritual AI VM with stateful precompiles for various model operations (inference, FT, quantization, embeddings)
- supports Ethereum base chain and rollups, alt L1 support coming in 2024

- tech pillars
    - censorship resistance and decentralization
    - privacy
    - computational integrity
    - incentives

- infernet: network for inference
    - take smart contract, plug into model
    - allows you to customize infra
    - set up nodes yourself, run inference for your products

- frenrug
    - on-chain smart agent that buys and sells friend.tech keys if you can convince it
    - built on internet SDKs
    - internet llm nodes generate responses, feeds into on-chain classifier (with ezkl proof)github.com/frenrug/contracts
    - frenrug.com

<https://twitter.com/niraj><br><https://ritual.net><br><https://x.com/niraj><br><niraj@ritual.net>

## Akash Network - Greg Osuri

Akash is open-source Supercloud that lets users buy and sell computing resources securely and efficiently. Purpose-built for public utility.

Greg's demo showcased the options available on the network and the ability to spin up new services.

<https://akash.network>
<https://twitter.com/gregosuri>

**Key points**
- GPUs are hard to get on demand
github.com/akash-network/community

- console.akash.network/analytics

- e.g. 1k/mo H100
https://pixart-alpha.github.io/

- ray compatible

- a100 utilization 95%

- $300m incentives coming online next year

## Agora Labs - Anish

Cloud-agnostic MLOps/LLMOps platform powered by cheap, decentralized compute.

<https://twitter.com/agora_io>

### render network

**Key points**
- OG in crypto space
- pioneered first use case for GPUs
- process of rendering is converting 3d model into pixels
- takes a lot of compute power
- used to take a day
- goal to provide fast, affordable rendering
- 25M frames rendered on network to date
- waitlist of GPUs over a million long

@drjonessf

BitTensor

- Beff Jezos' Thermodynamic computer

- AHaH Controller
	- a trillion synapses per clock cycle
	- energy based not transistor based

- Instead of loss landscapes, lowering error
	- Let’s build incentive landscapes, get more profit
	- Pay them not for adapting weights but all sorts of things

- Lower error on neural network
- Faster inference
- better gradients
- more information

- get paid for having GA lower loss
- sucking up compute and innovation
- passed OpenAI’s loss on GPT2 (trained in 2016)
- 31.39 vs 34.9 perplexity

bittensor.com/docs
https://docs.bittensor.com/

FreedomGPT

- SmarterChild: conversational AI
- robot you could talk to on AOL IM when no one was there
	- pretty dumb
	- step above a Liza
	- you could make your own, have it talk to other people, look at conversations
	- sometimes it would say “i’m not going to answer that”
	- chilling effect
	- happening again now

- sold mutual mobile a year ago
- 400 person a year go making dgitial products for f1000
- did a lot with AI
- sold it, started playing with ChatGPT about a year ago
- had birthday party for chatgpt last week
- a year ago decided to create FreedomGPT
- app store for AI
- first model: trying to get to parity of ChatGPT using Luna, 3d gradient descent
- model would answer anything
- 2 million people trying it out

- as capability increase, censorship and prohibition increase

- as capability increases, privacy and liberty decreases don’t use it if you’re not sure things will remain private

- they will make it illegal to access under penalty of death (treason)

- midjourney bans Xi, Jinping

--------

- technology is what allows freedom to exist
- belief: freedom is assured by documents
- reality” freedom assured by access to sufficiently advanced knowledge & technology over  
- those wanting ot take your freedom away

- these are munitions we need them otherwise they will be used against us and they already are

- fall of Constantinople by ottoman empire - gunpowder

- Gutenberg printing press caused nation to fall and US became independent

- war of 1812, attacked library of congress where books were

- those that start by burning books, will end by burning men heinrich heine

- how much more powerful is AI than books? 10x?1000x?

- thought experiment
	- imagine an AI that people star tto trust nearly 100% of the time

	- the problem isn’t if AI says something incorrect it’s as if AI starts saying too many correct things

	- e.g. “ted cdruz is zodiac killer”
   
- our predictions
	- ai public/private censorship timeline

	- 18 months (may 2025) accessing many AIs in the US will be on par with 		
- pharmaceutical RXs (if you can prove you need it, you can access)
	- 24 months, powerful AIs will require a process similar to obtaining a firearm with background checks and waiting periods. 
	- misuse will result in permanent revocation. numerous AIs will be banned from being indexed in search engine or even mentioned by the AIs that re deemed “publicly safe”

- Within 36 months, access to most powerful AIs will be restricted

- decentralizing freedom of compute because there is no other option

- freedom != free
- open sourced project reached #3 ranking on github
- over 700k installs of free desktop app
- cloud version generates $1k daily revenue
- banned from multiple hosting providers
- cease and desist from twitter/x and other
- prohibited from being discussed on facebook/meta properties
- +40 multimodal AI models with plans for 4k in 2023
- tons of hate mail and threats to get us shut down

- shortly after launching TwitterGPT, got banned (after elon acquisition)
now back on twitter

- team background
	- created products currently used by over a billion monthly users
	- collectively hired over 1k engineers/designers/PMs since founding mutual mobile
	- built +250MM in digital products for companies like google nike, and dozens of banks
	- built dozens of ML/predictive analytics solutions

- 2 groups of users
	- ~3k paid
	-  ~400k free

- plan is to start paying those nodes
- been cancelled from multiple web hosts
- one is now allowing us
- matter of time before they pull the plug

- freedomgpt-git-edge-node-ageofaicapital-s-team.vercel.app
- https://edge.freedomgpt.com/?ref=node-signup
- earn $30/day running inference

## EdgeLLama

### Varun Mathur

EdgeLLama, and the associated set of products, which lead to a seamless AI consumer-cloud will impose a similar abundant forcing function on AI as well. You can go ahead and cancel your $20/month Pro plans, because this next wave of AI, runs in your laptops, desktops and smartphones, and is good enough.

<https://twitter.com/varun_mathur><br><https://hyperspace.computer/><br>


## Nous Research
Self-Improving AI 
Nous Research is a private applied research group. We publish open-source work in the LLM domain, including local models, datasets, and core architectural improvements.

The demo included a walkthrough of the Nous software.  It showed the ability to build AI via drag and drop.  Am explanation of their research described YaRN, Hermes, Obsidian, and Capybara.

**Key points**

- Started three years ago
- four founders crypto people who found AI in different ways
- “fuck openAI” brought them together
- what can we do to open up again
- not negative, pushing against them
- provide a space for more humanistic AI
- 6 full time contributors
- 48 volunteer AI researchers
- thousands of contributors

- open source modles
	- OpenHermes 2.5
		- top used 7b
	- capybara
		- 34b amplify-instruct
	- obsidian
	- stablelm + openclip + capybara

- open research
- yarn
- muse: generative CoT reward model
- vulcan: chatML extension
- SYNTHIA

- Nous Forge
	- desktop app for interfacing with and composing open source and other AI models
- Obsidian multi-modal model
	- focussed on edge devices



most robust agents are breaking after 5 runs


<https://nousresearch.com/><br><https://huggingface.co/NousResearch><br><https://discord.gg/jqVphNsB4H>

## io.net - Angela Yi

- io.net is a state-of-the-art decentralized computing network that allows machine learning engineers to access distributed Cloud clusters at a small fraction of the cost of comparable centralized services.

- io.net deploys GPU clusters from multiple locations that are not constrained by colocated devices. The platform supports clusters of any scale, allowing engineers to deploy a 20K GPU cluster within seconds.

io.net has 3 key elements:
    1. IO Cloud, where engineers can seamlessly deploy their GPU clusters.
    2. IO Workers, where suppliers can connect their devices, monitor their performance, and keep track of their earnings and rewards.
    3. IO Explorer, where we provide transparent, real-time information on pricing, as well as devices and clusters, and inferences powered through our network.

<https://io.net/>
<https://discord.gg/65y7Kma4>
<https://t.me/ionet_official>

## Commune AI

Commune is a protocol that aims to connect all developer tools into one network, fostering a more shareable, reusable, and open economy. It follows an inclusive design philosophy that is based on being maximally unopinionated. This means that developers can leverage Commune as a versatile set of tools alongside their existing projects and have the freedom to incorporate additional tools that they find valuable.

<https://twitter.com/communeaidotorg>

### Upshot - Nick Evans

- Upshot: AI Network optimzied for financial applications
- powered by proof opf alpha protocol
- reward people by how useful for financial markets

- why focus on financial pplications?
	- build tools that can enable creation fo financial markets for anything
	- riskless society
	- efficient enough markest that every risk can be hedged
	- cryp is olargely financial innovation
	- financialization has been one of main usec ases
	- more conducive for trustless/verifiable form factors

- bacgkground
	- upshot one: peer prediction protocol for incentivizing honest responses to subjective questions
	- DMI Mcehanism:
	- dominantly truthful: truth tellling is dominant strategy
	- informed ftruthful: truth telling is  stricftly better than uinformative strategies
	- detail free: does not require prior knowledge to be inputted by mechanism designer
	- constant: only a constant number of questions and agents are required for it to be both dominantly truthful and informed-truthful

- findings
	- peer prediction doe simprove truth teslling incentives
	- network of human eactors lacks accuracy and scalability

- Upshot AI x Crypto Tooling
	- AI infrastructure for price predictions, network analyses, yield strategies, etc.
	- 2-5% MAPE (mean absolute percentage error)
	- 394m assets supported
	- <5 min update cadence
- findings
	- validated hypothesis around demand for AI x crypto systems
	- single entity creating models introduces scalability constraints and security rsisk

- solution
	- combine peer prediction protocol and AI x Crypto infra to build decentralized AI network optimized for financial applications

Upshot:
	- alpha miners establish contractual agreements on chain with dat providers
	- results in rev sharing from alpha minor work
	- share predictions with each other regularly
	- score each other’s predictions, leveraging peer prediction mechanism
	- incentivize them to share evaluations honestly

- big graph broken by topics
	- topic is defined by objective that is being collaoratively solved
	- output: mmeta model
	- data providers establish edges with alpha providers
	- alpha minors share predictions with each other, score predictions, scores aggregated, rewards distributed based on proof of alpha

- zkPredictor
	- alpha minors can pass around proofs verifying output of their work is result of underlying model they’re advertising
	- ensures tamper proof models
	- zkSNARK proof system optimized for tree-based models
	- verifies output of initial models on upshot network approaching 10k predictions per hour

Robonet:
- fist application that builds on Upshot and zkPredictor
- DeFi vaults with AI-Powered Yield Strategies
- smart contracts are limited compute environments
- AI is better at making sense of large amounts of data

	1. users deposit capital into robonet vaults.
	2. 2 strategies are instantiated as “optics” on upshot network
	3. upshot
	4. fees are shared between upshot peers contributing to the strategies and capital providers

- people who have unique insights no longer need capital or structure to profit off insights

- benefits
	- more diverse, expressive strategies
	- support for more long tail categories
	- cryptographically verified models
	- potential for much higher yield

http://upshot.xyz


## Actioneer - David Orban

Dignity and purpose for 8 billion humans in an age of AI

<https://twitter.com/davidorban>
<https://github.com/actioneerai>

## OpenCog Hyperon

The open-source software framework bringing together multiple AI paradigms in a cognitive architecture oriented toward AGI at the human level and beyond

<https://twitter.com/OpenCog>
<https://github.com/opencog>

## Hypercycle

HyperCycle is building a tiny but essential component that enables AI Machines to transact with other AI machines in a sub-second finality which results in unprecedented emergence.

<https://twitter.com/hypercycle_ai>

## The Lifted Initiative

### Eric Bravick

The Lifted Initiative is building a comprehensive web3 native cloud with a focus on easy to use tooling.  We've launched about 17 product and service groups to date into private Beta, including support of AI use cases.  We go public in 2024 and we are currently seeking integrations with other AI focused networks.  We believe strongly in decentralization of networks (multi-network approaches) and will be embracing a wide array of partnerships rather than a "build it all on one chain" philosophy.

<https://twitter.com/ebravick>

##Pannel Discussion
#### Ryan @ Modulus Labs
- previously AI research at Stanford
- worked in tech finance stuff
- decentralization promise and power of AI was so cool
- modulus is leading company crafting zero knowledge proofs for ML inference

#### Ben @ Gensyn
- machine learning compute protocol
- provide ability for anyone with ML capable compute device to offer that device to anyone in the world to train AI model
- pure hardware incentives
- previously ML researcher

#### Casey
- ML work at google as engineer
- partner at Paradigm

- most important now?
- smart contracts can’t harness power of AI
- missing key functionality that web2 has which is power of AI
- bc AI models are huge
- billions of parameters, gigaflops to teraflops of compute to perform
- gas cost on L2s cost 10s of thousands to millions to run single inference in trustless manner
- zero knowledge proof
- proof cf correct computation
